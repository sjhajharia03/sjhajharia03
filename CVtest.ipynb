{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f83c717-d362-49a9-a037-bb6a349c9b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pandas_ta as ta\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9bc0795c-f3c8-4c6c-9ef5-f1af4e92a89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_adj_close(px_raw: pd.DataFrame) -> pd.Series:\n",
    "    \n",
    "    if px_raw.empty:\n",
    "        raise ValueError(\"Empty price frame from yfinance.\")\n",
    "    \n",
    "    cols = px_raw.columns\n",
    "    if not isinstance(cols, pd.MultiIndex):\n",
    "        if 'Adj Close' not in px_raw.columns:\n",
    "            raise ValueError(f\"'Adj Close' not in columns: {list(px_raw.columns)}\")\n",
    "        s = px_raw['Adj Close']\n",
    "    else:\n",
    "        # usual multi-ticker layout: level 0 = field, level 1 = ticker\n",
    "        if 'Adj Close' in cols.get_level_values(0):\n",
    "            sub = px_raw['Adj Close']\n",
    "        elif 'Adj Close' in cols.get_level_values(1):\n",
    "            sub = px_raw.xs('Adj Close', axis=1, level=1)\n",
    "        else:\n",
    "            raise ValueError(\"Could not find 'Adj Close' in MultiIndex columns.\")\n",
    "        if isinstance(sub, pd.DataFrame):\n",
    "            if sub.shape[1] != 1:\n",
    "                raise ValueError(f\"Multiple tickers detected: {list(sub.columns)}. Fetch one ticker.\")\n",
    "            s = sub.iloc[:, 0]\n",
    "        else:\n",
    "            s = sub\n",
    "\n",
    "    return s.dropna().rename('adj_close')\n",
    "\n",
    "def _log_returns_no_nan(price: pd.Series) -> pd.Series:\n",
    "    \"\"\"Vectorized log returns starting at row 2 (never creates a NaN).\"\"\"\n",
    "    v = price.astype(float).to_numpy()\n",
    "    if v.size < 2:\n",
    "        return pd.Series(index=price.index[0:0], dtype=float, name='r_t')\n",
    "    lr = np.log(v[1:] / v[:-1])\n",
    "    return pd.Series(lr, index=price.index[1:], name='r_t')\n",
    "\n",
    "def _rsi14(price: pd.Series) -> pd.Series:\n",
    "    rsi = ta.rsi(price, length=14)\n",
    "    if isinstance(rsi, pd.DataFrame):\n",
    "        rsi = rsi.iloc[:, 0]\n",
    "    if rsi is None or rsi.isna().all():\n",
    "        delta = price.diff()\n",
    "        gain = delta.clip(lower=0)\n",
    "        loss = -delta.clip(upper=0)\n",
    "        n = 14\n",
    "        avg_gain = gain.ewm(alpha=1/n, adjust=False, min_periods=n).mean()\n",
    "        avg_loss = loss.ewm(alpha=1/n, adjust=False, min_periods=n).mean()\n",
    "        rs = avg_gain / avg_loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi.rename('rsi_14')\n",
    "\n",
    "def create_dataset(ticker=\"^GSPC\", start_date=\"2015-01-01\", end_date=\"2024-03-31\",\n",
    "                   horizon=1, lookback_days=40):\n",
    "    \"\"\"\n",
    "    Fetches data and engineers features/labels with no NaNs by construction.\n",
    "    - Log returns start at row 2 (no top NaN).\n",
    "    - Warmup handled by rolling 'min_periods', final dropna keeps only valid rows.\n",
    "    \"\"\"\n",
    "    print(f\"Creating dataset for {ticker} from {start_date} to {end_date}â€¦\")\n",
    "\n",
    "    fetch_start = pd.to_datetime(start_date) - pd.Timedelta(days=lookback_days)\n",
    "    px_raw = yf.download(ticker, start=fetch_start, end=end_date, auto_adjust=False, progress=False)\n",
    "    if px_raw.empty:\n",
    "        raise ValueError(f\"No data downloaded for {ticker}. Check ticker/dates.\")\n",
    "\n",
    "    price = _extract_adj_close(px_raw)\n",
    "\n",
    "    # r_t (no NaN at top), align price to r_t index\n",
    "    r_t = _log_returns_no_nan(price)\n",
    "    price = price.loc[r_t.index]\n",
    "\n",
    "    # base frame aligned from row 2 onward\n",
    "    base = pd.DataFrame({'adj_close': price, 'r_t': r_t}, index=r_t.index)\n",
    "\n",
    "    # --- Features (as-of t) ---\n",
    "    feats = pd.DataFrame(index=base.index)\n",
    "\n",
    "    # Lagged returns\n",
    "    for lag in [1, 2, 5, 10]:\n",
    "        feats[f'r_t_{lag}'] = base['r_t'].shift(lag)\n",
    "\n",
    "    # Rolling stats on returns (full windows only)\n",
    "    for w in [5, 10, 20]:\n",
    "        feats[f'vol_{w}']  = base['r_t'].rolling(w, min_periods=w).std(ddof=0)\n",
    "        feats[f'mean_{w}'] = base['r_t'].rolling(w, min_periods=w).mean()\n",
    "\n",
    "    # RSI(14) on price (as-of t)\n",
    "    feats['rsi_14'] = _rsi14(base['adj_close'])\n",
    "\n",
    "    # 20-day high/low distances (full windows)\n",
    "    roll_max = base['adj_close'].rolling(20, min_periods=20).max()\n",
    "    roll_min = base['adj_close'].rolling(20, min_periods=20).min()\n",
    "    feats['dist_high_20'] = base['adj_close'] / roll_max - 1.0\n",
    "    feats['dist_low_20']  = base['adj_close'] / roll_min - 1.0\n",
    "\n",
    "    # Calendar features\n",
    "    feats['dow']   = feats.index.dayofweek   # 0..6 (Mon..Sun)\n",
    "    feats['month'] = feats.index.month       # 1..12\n",
    "\n",
    "    # --- Label: y_t = r_{t+1} ---\n",
    "    y = base['r_t'].shift(-horizon).rename('label')\n",
    "\n",
    "    # --- Final alignment ---\n",
    "    full = pd.concat([feats, y], axis=1).dropna()\n",
    "    full = full.loc[pd.to_datetime(start_date):]  # cut off warmup padding before start_date\n",
    "\n",
    "    if full.empty:\n",
    "        raise SystemError(\"Empty dataset after alignment. Check date range and that enough data exists.\")\n",
    "\n",
    "    X = full.drop(columns='label')\n",
    "    y = full['label']\n",
    "    r_t_aligned = base['r_t'].reindex(X.index)\n",
    "\n",
    "    print(f\"Dataset ready. Features shape: {X.shape}, Label shape: {y.shape}\")\n",
    "    return X, y, r_t_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93d64d82-e4e6-4b10-9a9b-f2606c738df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WalkForwardExpanding:\n",
    "    def __init__(self, step=250, min_train=500):\n",
    "        self.step = int(step)\n",
    "        self.min_train = int(min_train)\n",
    "    def split(self, X):\n",
    "        n = len(X)\n",
    "        for t_end in range(self.min_train, n, self.step):\n",
    "            te_start, te_stop = t_end, min(t_end + self.step, n)\n",
    "            if te_start >= te_stop:\n",
    "                break\n",
    "            yield np.arange(0, t_end), np.arange(te_start, te_stop)\n",
    "\n",
    "class PurgedKFoldEmbargo:\n",
    "    def __init__(self, n_splits=5, purge=20, embargo=5):\n",
    "        self.n_splits = int(n_splits)\n",
    "        self.purge = int(purge)\n",
    "        self.embargo = int(embargo)\n",
    "    def split(self, X):\n",
    "        n = len(X)\n",
    "        idx = np.arange(n)\n",
    "        fold_sizes = np.full(self.n_splits, n // self.n_splits, dtype=int)\n",
    "        fold_sizes[: n % self.n_splits] += 1\n",
    "        start = 0\n",
    "        for size in fold_sizes:\n",
    "            stop = start + size\n",
    "            test_idx = idx[start:stop]\n",
    "\n",
    "            mask = np.ones(n, dtype=bool)\n",
    "            # remove test itself\n",
    "            mask[start:stop] = False\n",
    "            # purge: remove neighbors around test\n",
    "            ps = max(0, start - self.purge)\n",
    "            pe = min(n, stop + self.purge)\n",
    "            mask[ps:pe] = False\n",
    "            # embargo: remove days right after test\n",
    "            es = stop\n",
    "            ee = min(n, stop + self.embargo)\n",
    "            mask[es:ee] = False\n",
    "\n",
    "            train_idx = idx[mask]\n",
    "            yield train_idx, test_idx\n",
    "            start = stop\n",
    "\n",
    "# metrics \n",
    "\n",
    "def info_coefficient(y_true, y_pred):\n",
    "    if len(y_true) < 2:\n",
    "        return np.nan\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "\n",
    "def hit_rate(y_true, y_pred):\n",
    "    return (np.sign(y_true) == np.sign(y_pred)).mean()\n",
    "\n",
    "# evaluator\n",
    "\n",
    "def evaluate_cv(model, X: pd.DataFrame, y: pd.Series, splitter, scale=True, random_state=42):\n",
    "    yhat_chunks, ytrue_chunks, idx_chunks = [], [], []\n",
    "\n",
    "    for tr, te in splitter.split(X):\n",
    "        # --- 1) slice\n",
    "        X_tr, X_te = X.iloc[tr], X.iloc[te]\n",
    "        y_tr, y_te = y.iloc[tr], y.iloc[te]\n",
    "\n",
    "        # --- 2) scale within-train only\n",
    "        if scale:\n",
    "            scaler = StandardScaler().fit(X_tr)\n",
    "            X_tr = scaler.transform(X_tr)\n",
    "            X_te = scaler.transform(X_te)\n",
    "\n",
    "        # --- 3) reinit model fresh (no state carry)\n",
    "        est = model.__class__(**getattr(model, \"get_params\")())\n",
    "        if hasattr(est, \"random_state\"):\n",
    "            est.random_state = random_state\n",
    "\n",
    "        # --- 4) fit & predict\n",
    "        est.fit(X_tr, y_tr)\n",
    "        yhat = est.predict(X_te)\n",
    "\n",
    "        # --- 5) collect\n",
    "        yhat_chunks.append(yhat)\n",
    "        ytrue_chunks.append(y_te.values)\n",
    "        idx_chunks.append(y_te.index)\n",
    "\n",
    "    # --- 6) concatenate OOS\n",
    "    y_pred = np.concatenate(yhat_chunks) if yhat_chunks else np.array([])\n",
    "    y_true = np.concatenate(ytrue_chunks) if ytrue_chunks else np.array([])\n",
    "    idx = pd.Index(np.concatenate([i.values for i in idx_chunks])) if idx_chunks else pd.Index([])\n",
    "\n",
    "    # --- 7) metrics\n",
    "    if len(y_true) == 0:\n",
    "        raise RuntimeError(\"Splitter produced no test samples. Check your min_train/step or n_splits/purge/embargo.\")\n",
    "\n",
    "    metrics = {\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"IC\": info_coefficient(y_true, y_pred),\n",
    "        \"HitRate\": hit_rate(y_true, y_pred),\n",
    "        \"N_test\": len(y_true)\n",
    "    }\n",
    "    y_pred_series = pd.Series(y_pred, index=idx).sort_index()\n",
    "    return metrics, y_pred_series\n",
    "\n",
    "# runner to compare models \n",
    "\n",
    "def compare_models_splitters(X, y, models: dict, splitters: dict, scale=True):\n",
    "    rows = []\n",
    "    oos_preds = {}\n",
    "    for s_name, splitter in splitters.items():\n",
    "        for m_name, model in models.items():\n",
    "            metrics, yhat = evaluate_cv(model, X, y, splitter, scale=scale)\n",
    "            rows.append({\"Splitter\": s_name, \"Model\": m_name, **metrics})\n",
    "            oos_preds[(s_name, m_name)] = yhat\n",
    "    results = pd.DataFrame(rows).sort_values([\"Splitter\", \"Model\"]).reset_index(drop=True)\n",
    "    return results, oos_preds\n",
    "\n",
    "# verification\n",
    "\n",
    "def inspect_splits(splitter, X, k=3):\n",
    "    i = 0\n",
    "    for tr, te in splitter.split(X):\n",
    "        print(f\"Split {i}: train[{len(tr)}] {X.index[tr[0]].date()} â†’ {X.index[tr[-1]].date()}  \"\n",
    "              f\"| test[{len(te)}] {X.index[te[0]].date()} â†’ {X.index[te[-1]].date()}\")\n",
    "        i += 1\n",
    "        if i >= k: break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2ddc961-2d99-4495-98bd-1dd3ad151d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0: train[500] 2015-01-02 â†’ 2016-12-23  | test[250] 2016-12-27 â†’ 2017-12-21\n",
      "Split 1: train[750] 2015-01-02 â†’ 2017-12-21  | test[250] 2017-12-22 â†’ 2018-12-20\n",
      "Split 2: train[1000] 2015-01-02 â†’ 2018-12-20  | test[250] 2018-12-21 â†’ 2019-12-18\n",
      "Split 0: train[1839] 2016-12-05 â†’ 2024-03-27  | test[465] 2015-01-02 â†’ 2016-11-03\n",
      "Split 1: train[1819] 2015-01-02 â†’ 2024-03-27  | test[465] 2016-11-04 â†’ 2018-09-11\n",
      "Split 2: train[1819] 2015-01-02 â†’ 2024-03-27  | test[465] 2018-09-12 â†’ 2020-07-17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Splitter</th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>IC</th>\n",
       "      <th>HitRate</th>\n",
       "      <th>N_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KFold(lie)</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.007502</td>\n",
       "      <td>0.014110</td>\n",
       "      <td>0.503873</td>\n",
       "      <td>2324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KFold(lie)</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.007423</td>\n",
       "      <td>-0.034345</td>\n",
       "      <td>0.530120</td>\n",
       "      <td>2324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KFold(lie)</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.015086</td>\n",
       "      <td>0.505164</td>\n",
       "      <td>2324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Purged+Emb</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.007528</td>\n",
       "      <td>-0.001885</td>\n",
       "      <td>0.518072</td>\n",
       "      <td>2324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Purged+Emb</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.007472</td>\n",
       "      <td>-0.053592</td>\n",
       "      <td>0.523236</td>\n",
       "      <td>2324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Purged+Emb</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>-0.003904</td>\n",
       "      <td>0.501721</td>\n",
       "      <td>2324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WalkFwd</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.007788</td>\n",
       "      <td>-0.006127</td>\n",
       "      <td>0.495066</td>\n",
       "      <td>1824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WalkFwd</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.007817</td>\n",
       "      <td>-0.030391</td>\n",
       "      <td>0.516447</td>\n",
       "      <td>1824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WalkFwd</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>-0.025892</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>1824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Splitter       Model       MSE       MAE        IC   HitRate  N_test\n",
       "0  KFold(lie)  ElasticNet  0.000132  0.007502  0.014110  0.503873    2324\n",
       "1  KFold(lie)          RF  0.000133  0.007423 -0.034345  0.530120    2324\n",
       "2  KFold(lie)       Ridge  0.000133  0.007600  0.015086  0.505164    2324\n",
       "3  Purged+Emb  ElasticNet  0.000133  0.007528 -0.001885  0.518072    2324\n",
       "4  Purged+Emb          RF  0.000132  0.007472 -0.053592  0.523236    2324\n",
       "5  Purged+Emb       Ridge  0.000137  0.007661 -0.003904  0.501721    2324\n",
       "6     WalkFwd  ElasticNet  0.000148  0.007788 -0.006127  0.495066    1824\n",
       "7     WalkFwd          RF  0.000157  0.007817 -0.030391  0.516447    1824\n",
       "8     WalkFwd       Ridge  0.000153  0.007949 -0.025892  0.491228    1824"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitters = {\n",
    "    \"KFold(lie)\": KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    \"WalkFwd\":    WalkForwardExpanding(step=250, min_train=500),\n",
    "    \"Purged+Emb\": PurgedKFoldEmbargo(n_splits=5, purge=20, embargo=5),\n",
    "}\n",
    "\n",
    "inspect_splits(splitters[\"WalkFwd\"], X)\n",
    "inspect_splits(splitters[\"Purged+Emb\"], X)\n",
    "\n",
    "models = {\n",
    "    \"Ridge\": Ridge(alpha=1.0, random_state=42),\n",
    "    \"ElasticNet\": ElasticNet(alpha=0.001, l1_ratio=0.2, max_iter=5000, random_state=42),\n",
    "    \"RF\": RandomForestRegressor(n_estimators=200, max_depth=4, random_state=42, n_jobs=-1),\n",
    "}\n",
    "\n",
    "# Compare\n",
    "results, oos_preds = compare_models_splitters(X, y, models, splitters, scale=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e05b2ac-f9b0-4d6a-9253-62bbee9b9672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
